{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan_models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZuK80wtTKAJ"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8T5hNoSRher",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2c3b798-9ddd-4748-c334-2eada7f72f1d"
      },
      "source": [
        "!pip install sdv\n",
        "from sdv.tabular import GaussianCopula, CTGAN, CopulaGAN, TVAE\n",
        "from sdv.evaluation import evaluate\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sdv\n",
            "  Downloading sdv-0.15.0-py2.py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2,>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from sdv) (1.3.5)\n",
            "Collecting graphviz<1,>=0.13.2\n",
            "  Downloading graphviz-0.20-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from sdv) (1.21.6)\n",
            "Collecting deepecho<0.4,>=0.3.0.post1\n",
            "  Downloading deepecho-0.3.0.post1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting copulas<0.8,>=0.7.0\n",
            "  Downloading copulas-0.7.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5,>=4.15 in /usr/local/lib/python3.7/dist-packages (from sdv) (4.64.0)\n",
            "Collecting rdt<0.7,>=0.6.2\n",
            "  Downloading rdt-0.6.4-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting Faker<10,>=3.0.0\n",
            "  Downloading Faker-9.9.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 32.8 MB/s \n",
            "\u001b[?25hCollecting ctgan<0.6,>=0.5.1\n",
            "  Downloading ctgan-0.5.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting sdmetrics<0.6,>=0.5.0\n",
            "  Downloading sdmetrics-0.5.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting scipy<2,>=1.5.4\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting matplotlib<4,>=3.4.0\n",
            "  Downloading matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.1->sdv) (1.11.0+cu113)\n",
            "Requirement already satisfied: scikit-learn<2,>=0.24 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.1->sdv) (1.0.2)\n",
            "Requirement already satisfied: torchvision<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.1->sdv) (0.12.0+cu113)\n",
            "Requirement already satisfied: packaging<22,>=20 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.1->sdv) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/dist-packages (from Faker<10,>=3.0.0->sdv) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.2 in /usr/local/lib/python3.7/dist-packages (from Faker<10,>=3.0.0->sdv) (4.2.0)\n",
            "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.7/dist-packages (from Faker<10,>=3.0.0->sdv) (1.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (3.0.9)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
            "\u001b[K     |████████████████████████████████| 930 kB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>=1.1.3->sdv) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.4->Faker<10,>=3.0.0->sdv) (1.15.0)\n",
            "Collecting pyyaml<6,>=5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting psutil<6,>=5.7\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2,>=0.24->ctgan<0.6,>=0.5.1->sdv) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2,>=0.24->ctgan<0.6,>=0.5.1->sdv) (1.1.0)\n",
            "Collecting pyts<0.13.0,>=0.12.0\n",
            "  Downloading pyts-0.12.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts<0.13.0,>=0.12.0->sdmetrics<0.6,>=0.5.0->sdv) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts<0.13.0,>=0.12.0->sdmetrics<0.6,>=0.5.0->sdv) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts<0.13.0,>=0.12.0->sdmetrics<0.6,>=0.5.0->sdv) (57.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.1->sdv) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.1->sdv) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.1->sdv) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.1->sdv) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.1->sdv) (2022.5.18.1)\n",
            "Installing collected packages: scipy, fonttools, pyyaml, psutil, matplotlib, rdt, pyts, copulas, sdmetrics, graphviz, Faker, deepecho, ctgan, sdv\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Faker-9.9.1 copulas-0.7.0 ctgan-0.5.1 deepecho-0.3.0.post1 fonttools-4.33.3 graphviz-0.20 matplotlib-3.5.2 psutil-5.9.1 pyts-0.12.0 pyyaml-5.4.1 rdt-0.6.4 scipy-1.7.3 sdmetrics-0.5.0 sdv-0.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsZrzjp_TGJH"
      },
      "source": [
        "## Load the data from CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMBQnuDBPJ1g"
      },
      "source": [
        "def load_dataset(benchmark, algo):\n",
        "  df_orig=pd.read_csv(drive_location+algo+\".csv\")\n",
        "  #print(df_orig)\n",
        "  #df_selected_col = df_orig.drop(columns=['sys','sysname','arch','PS','executable'])\n",
        "  if (benchmark == \"SPEC2006\" or benchmark == \"SPEC2017\"):\n",
        "    df_selected_col=df_orig.drop(columns=['arch','ld_shared_by_cores','l2_shared_by_cores','no_of_threads','system_name','bus_speed_qpi','bus_speed_dmi','l1_ins_assoc','l1_data_assoc','l2_assoc','l3_assoc','raw_bus_speed','converted_bus_speed','ddr_type','runtime'])\n",
        "  elif (benchmark == \"NPB\"):\n",
        "    df_selected_col=df_orig.drop(columns=['sys','sysname','arch','l1d_assoc','l1d_cache_lines','l1d_shared_by_threads','l2_assoc','l2_cache_lines','l2_shared_by_threads','l3_assoc','l3_cache_lines','l3_shared_by_threads','PS','runtime','executable','system'])\n",
        "  else:\n",
        "    df_selected_col=df_orig.drop(columns=['sys','arch','l1d_assoc','l1d_cache_lines','l1d_shared_by_threads','l2_assoc','l2_cache_lines','l2_shared_by_threads','l3_assoc','l3_cache_lines','l3_shared_by_threads','runtime'])\n",
        "  #print(df_selected_col)\n",
        "  df_selected_col.dropna(inplace=True)\n",
        "  #print(df_selected_col)\n",
        "  return df_selected_col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vi5iwkJTRn5"
      },
      "source": [
        "## Implementation of Vanilla GAN (Generator and Descriminitor)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue8hHMbKTBRw"
      },
      "source": [
        "def make_generator(gentype='vanila'):\n",
        "  if gentype == 'vanila':\n",
        "    return vanila_model()\n",
        "  elif gen_type == 'ctgan':\n",
        "    return\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vanila_model():\n",
        "    vanila_model = tf.keras.Sequential()\n",
        "    vanila_model.add(tf.keras.layers.Dense(7,activation='relu',use_bias=False,input_dim=df.shape[1]*2))\n",
        "    vanila_model.add(tf.keras.layers.Dense(7,activation='relu',use_bias=False))\n",
        "    vanila_model.add(tf.keras.layers.Dense(7,activation='relu',use_bias=False))\n",
        "    vanila_model.add(tf.keras.layers.Dense(df.shape[1],activation='sigmoid',use_bias=False))\n",
        "    return vanila_model"
      ],
      "metadata": {
        "id": "gAaC32-1xv2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TVAE "
      ],
      "metadata": {
        "id": "BxcFXHGh4Gfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tvae_generator(tvae_model):\n",
        "  real_data = pd.read_csv(drive_location+algo+\"_real_data.csv\")\n",
        "  tvae_model.fit(real_data)\n",
        "  fake_data = tvae_model.sample(100)\n",
        "  return tvae_model, fake_data"
      ],
      "metadata": {
        "id": "i4YuefiK4Kma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evolutionary_tvae(algo):\n",
        "  real_data = pd.read_csv(drive_location+algo+\"_real_data.csv\")\n",
        "  tvae_model, fake_data = tvae_generator(TVAE())\n",
        "  #print(evaluate(fake_data, real_data, metrics=['CSTest', 'KSTest'], aggregate=False))\n",
        "  score = evaluate(fake_data, real_data, metrics=['CSTest', 'KSTest'])\n",
        "  prev_score = 0\n",
        "  fake_data.to_csv(drive_location+algo+\"_tvae_fake_data.csv\",index=False)\n",
        "  print(\"copulagan fake vs real score=\",score,\" prev_score=\",prev_score)\n",
        "  '''\n",
        "  while prev_score < score:\n",
        "    prev_model = tvae_model\n",
        "    tvae_model, synthetic_data = tvae_generator(tvae_model, real_data)\n",
        "    prev_score = score\n",
        "    score = evaluate(synthetic_data, real_data, metrics=['CSTest', 'KSTest'])\n",
        "    print(\"score=\",score,\" prev_score=\",prev_score)\n",
        "  '''"
      ],
      "metadata": {
        "id": "CDLnp4g94MqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CopulaGAN"
      ],
      "metadata": {
        "id": "_zgc0qpw1k9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def copulagan_generator(copulagan_model):\n",
        "  real_data = pd.read_csv(drive_location+algo+\"_real_data.csv\")\n",
        "  copulagan_model.fit(real_data)\n",
        "  fake_data = copulagan_model.sample(100)\n",
        "  return copulagan_model, fake_data"
      ],
      "metadata": {
        "id": "ANUl6xnW1niX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evolutionary_copulagan(algo):\n",
        "  real_data = pd.read_csv(drive_location+algo+\"_real_data.csv\")\n",
        "  copulagan_model, fake_data = copulagan_generator(GaussianCopula())\n",
        "  #print(evaluate(fake_data, real_data, metrics=['CSTest', 'KSTest'], aggregate=False))\n",
        "  score = evaluate(fake_data, real_data, metrics=['CSTest', 'KSTest'])\n",
        "  prev_score = 0\n",
        "  fake_data.to_csv(drive_location+algo+\"_copulagan_fake_data.csv\",index=False)\n",
        "  print(\"copulagan fake vs real score=\",score,\" prev_score=\",prev_score)\n",
        "  '''\n",
        "  while prev_score < score:\n",
        "    prev_model = copulagan_model\n",
        "    copulagan_model, synthetic_data = copulagan_generator(copulagan_model, real_data)\n",
        "    prev_score = score\n",
        "    score = evaluate(synthetic_data, real_data, metrics=['CSTest', 'KSTest'])\n",
        "    print(\"score=\",score,\" prev_score=\",prev_score)\n",
        "  '''"
      ],
      "metadata": {
        "id": "bTzblLp_2tQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GaussianCopula"
      ],
      "metadata": {
        "id": "9nkRsoYQxK2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussiancopula_generator(gaussiancopula_model):\n",
        "  real_data = pd.read_csv(drive_location+algo+\"_real_data.csv\")\n",
        "  gaussiancopula_model.fit(real_data)\n",
        "  fake_data = gaussiancopula_model.sample(100)\n",
        "  return gaussiancopula_model, fake_data"
      ],
      "metadata": {
        "id": "ZiID5BjGxKGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evolutionary_gaussiancopula(algo):\n",
        "  real_data = pd.read_csv(drive_location+algo+\"_real_data.csv\")\n",
        "  gaussiancopula_model, fake_data = gaussiancopula_generator(GaussianCopula())\n",
        "  #print(evaluate(fake_data, real_data, metrics=['CSTest', 'KSTest'], aggregate=False))\n",
        "  score = evaluate(fake_data, real_data, metrics=['CSTest', 'KSTest'])\n",
        "  prev_score = 0\n",
        "  fake_data.to_csv(drive_location+algo+\"_gaussiancopula_fake_data.csv\",index=False)\n",
        "  print(\"gaussiancopula fake vs real score=\",score,\" prev_score=\",prev_score)\n",
        "  '''\n",
        "  while prev_score < score:\n",
        "    prev_model = gaussiancopula_model\n",
        "    gaussiancopula_model, synthetic_data = gaussiancopula_generator(gaussiancopula_model, real_data)\n",
        "    prev_score = score\n",
        "    score = evaluate(synthetic_data, real_data, metrics=['CSTest', 'KSTest'])\n",
        "    print(\"score=\",score,\" prev_score=\",prev_score)\n",
        "  '''"
      ],
      "metadata": {
        "id": "XiovRRQ80QLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BajDtZUOsS9C"
      },
      "source": [
        "## CTGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjVVdlOSsWfs"
      },
      "source": [
        "def ctgan_generator(ctgan_model):\n",
        "  real_data = pd.read_csv(drive_location+algo+\"_real_data.csv\")\n",
        "  ctgan_model.fit(real_data)\n",
        "  fake_data = ctgan_model.sample(100)\n",
        "  return ctgan_model, fake_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evolutionary_ctgan(algo):\n",
        "  real_data = pd.read_csv(drive_location+algo+\"_real_data.csv\")\n",
        "  ctgan_model, fake_data = ctgan_generator(CTGAN())\n",
        "  #print(evaluate(fake_data, real_data, metrics=['CSTest', 'KSTest'], aggregate=False))\n",
        "  score = evaluate(fake_data, real_data, metrics=['CSTest', 'KSTest'])\n",
        "  prev_score = 0\n",
        "  fake_data.to_csv(drive_location+algo+\"_ctgan_fake_data.csv\",index=False)\n",
        "  print(\"CTGAN fake vs real score=\",score,\" prev_score=\",prev_score)\n",
        "  '''\n",
        "  while prev_score < score:\n",
        "    prev_model = ctgan_model\n",
        "    ctgan_model, synthetic_data = ctgan_generator(ctgan_model, real_data)\n",
        "    prev_score = score\n",
        "    score = evaluate(synthetic_data, real_data, metrics=['CSTest', 'KSTest'])\n",
        "    print(\"score=\",score,\" prev_score=\",prev_score)\n",
        "  '''"
      ],
      "metadata": {
        "id": "8eilCQnZtvSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Function to Genrate Synthetic Data from Fake Data"
      ],
      "metadata": {
        "id": "pDPDVnHj2jWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_from_fake(algo, gan_name):\n",
        "  fake_data = pd.read_csv(drive_location+algo+\"_\"+gan_name+\"_fake_data.csv\")\n",
        "  real_data = pd.read_csv(drive_location+algo+\"_real_data.csv\")\n",
        "  synthetic_data = fake_data.copy()\n",
        "  cols = fake_data.columns\n",
        "  #print(cols)\n",
        "  for index, row in fake_data.iterrows():\n",
        "    for col in cols:\n",
        "      if not(col == 'isa' or col == 'mem_type'):\n",
        "        result_index = real_data[col].sub(row[col]).abs().idxmin()\n",
        "        synthetic_data.loc[index, col] = real_data.loc[result_index, col]\n",
        "        #print('row[col]=',row[col], 'synthetic_data.loc[index, col]=', synthetic_data.loc[index, col], 'real_data.loc[result_index, col]=', real_data.loc[result_index, col])\n",
        "  synthetic_data.to_csv(drive_location+algo+\"_\"+gan_name+\"_synthetic_data.csv\",index=False)\n",
        "  print(gan_name,' synthetic vs real score',evaluate(synthetic_data, real_data, metrics=['CSTest', 'KSTest']))"
      ],
      "metadata": {
        "id": "cY11j_Iy8W_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6HA9XFAPwN_"
      },
      "source": [
        "## Main Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co_GPiEcPt8H",
        "outputId": "6ec083d3-a07a-491d-a3ac-9181bb0114c9"
      },
      "source": [
        "drive_location = r\"/content/drive/MyDrive/Summer_Internship/CodeFiles/\"\n",
        "\n",
        "# Mantevo Suite\n",
        "#benchmark = \"Mantevo\"\n",
        "#algo=\"mantevo_miniFE\"\n",
        "#algo_fname=\"runtimes_final_mantevo_miniFE\"\n",
        "# NPB Suite\n",
        "#benchmark = \"NPB\"\n",
        "#algo = \"npb_ep\"\n",
        "#algo_fname=\"runtimes_final_npb_ep\"\n",
        "#benchmark = \"NPB\"\n",
        "#algo = \"npb_mg\"\n",
        "#algo_fname=\"runtimes_final_npb_mg\"\n",
        "# SPEC 2006 Float\n",
        "#benchmark = \"SPEC2006\"\n",
        "#algo = \"leslie3d\"\n",
        "#algo_fname = \"437.leslie3d\"\n",
        "# SPEC 2006 Int\n",
        "#benchmark = \"SPEC2006\"\n",
        "#algo = \"perlbench\"\n",
        "#algo_fname = \"400.perlbench\"\n",
        "benchmark = \"SPEC2017\"\n",
        "algo = \"603.bwaves_s\"\n",
        "algo_fname = \"603.bwaves_s\"\n",
        "\n",
        "spec_float_benchmark_list = [\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2006\",\"SPEC2006\",\"SPEC2006\",\"SPEC2006\",\"SPEC2006\",\"SPEC2006\",\"SPEC2006\",\"SPEC2006\",\"SPEC2006\"]\n",
        "spec_float_algo_list = [\"603.bwaves_s\",\"607.cactuBSSN_s\",\"619.lbm_s\",\"621.wrf_s\",\"627.cam4_s\",\"628.pop2_s\",\"638.imagick_s\",\"644.nab_s\",\"649.fotonik3d_s\",\"654.roms_s\",\"416.gamess\",\"433.milc\",\"434.zeusmp\",\"435.gromacs\",\"437.leslie3d\",\"447.dealII\",\"450.soplex\",\"453.povray\",\"454.calculix\"]\n",
        "spec_float_algo_fname_list = [\"603.bwaves_s\",\"607.cactuBSSN_s\",\"619.lbm_s\",\"621.wrf_s\",\"627.cam4_s\",\"628.pop2_s\",\"638.imagick_s\",\"644.nab_s\",\"649.fotonik3d_s\",\"654.roms_s\",\"416.gamess\",\"433.milc\",\"434.zeusmp\",\"435.gromacs\",\"437.leslie3d\",\"447.dealII\",\"450.soplex\",\"453.povray\",\"454.calculix\"]\n",
        "\n",
        "spec_int_benchmark_list = [\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2017\",\"SPEC2006\",\"SPEC2006\",\"SPEC2006\",\"SPEC2006\",\"SPEC2006\"]\n",
        "spec_int_algo_list = [\"600.perlbench_s\",\"602.gcc_s\",\"605.mcf_s\",\"620.omnetpp_s\",\"623.xalancbmk_s\",\"625.x264_s\",\"631.deepsjeng_s\",\"641.leela_s\",\"648.exchange2_s\",\"657.xz_s\",\"401.bzip2\",\"456.hmmer\",\"458.sjeng\",\"462.libquantum\",\"473.astar\"]\n",
        "spec_int_algo_fname_list = [\"600.perlbench_s\",\"602.gcc_s\",\"605.mcf_s\",\"620.omnetpp_s\",\"623.xalancbmk_s\",\"625.x264_s\",\"631.deepsjeng_s\",\"641.leela_s\",\"648.exchange2_s\",\"657.xz_s\",\"401.bzip2\",\"456.hmmer\",\"458.sjeng\",\"462.libquantum\",\"473.astar\"]\n",
        "\n",
        "npb_other_benchmark_list = [\"NPB\",\"NPB\",\"NPB\",\"NPB\",\"OTHER\",\"OTHER\",\"OTHER\"]\n",
        "npb_other_algo_list = [\"npb_ep\",\"npb_mg\",\"npb_sp\",\"npb_sp-mz\",\"matmul\",\"montecarlo\",\"quicksort\"]\n",
        "npb_other_algo_fname_list = [\"npb_ep\",\"npb_mg\",\"npb_sp\",\"npb_sp-mz\",\"matmul\",\"montecarlo\",\"quicksort\"]\n",
        "\n",
        "\n",
        "# Assign variable with which list is to be processed\n",
        "benchmark_list = npb_other_benchmark_list\n",
        "algo_list = npb_other_algo_list\n",
        "algo_fname_list = npb_other_algo_fname_list\n",
        "#for algo_idx, algo in enumerate(algo_list):\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "# Load and preprocess real dataset\n",
        "real_data = load_dataset(benchmark, algo)\n",
        "real_data.to_csv(drive_location+algo+\"_real_data.csv\",index=False)\n",
        "\n",
        "# Generate fake data using GaussianCopula\n",
        "evolutionary_gaussiancopula(algo)\n",
        "# Convert fake data into synthetic data (To generate synthetic data we find a value in real data near to each fake data feature value and replace the fake data value to value from real data)\n",
        "generate_synthetic_from_fake(algo,'gaussiancopula')\n",
        "\n",
        "# Generate fake data using CTGAN\n",
        "evolutionary_ctgan(algo)\n",
        "# Convert fake data into synthetic data (To generate synthetic data we find a value in real data near to each fake data feature value and replace the fake data value to value from real data)\n",
        "generate_synthetic_from_fake(algo,'ctgan')\n",
        "\n",
        "# Generate fake data using CopulaGAN\n",
        "evolutionary_copulagan(algo)\n",
        "# Convert fake data into synthetic data (To generate synthetic data we find a value in real data near to each fake data feature value and replace the fake data value to value from real data)\n",
        "generate_synthetic_from_fake(algo,'copulagan')\n",
        "\n",
        "# Generate fake data using CopulaGAN\n",
        "evolutionary_tvae(algo)\n",
        "# Convert fake data into synthetic data (To generate synthetic data we find a value in real data near to each fake data feature value and replace the fake data value to value from real data)\n",
        "generate_synthetic_from_fake(algo,'tvae')\n",
        "\n",
        "# Vanilla GAN\n",
        "#generator_model = make_generator(gentype='vanila')\n",
        "#print(generator_model)\n",
        "\n",
        "#noise = tf.random.normal([1, 42])\n",
        "#generated_data = generator_model(noise, training=False)\n",
        "#print(generated_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gaussiancopula fake vs real score= 0.8089085125814354  prev_score= 0\n",
            "gaussiancopula  synthetic vs real score 0.9164052756371108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:282: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:146: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:146: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:282: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:282: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:146: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTGAN fake vs real score= 0.8915900766999835  prev_score= 0\n",
            "ctgan  synthetic vs real score 0.9359577935752532\n",
            "copulagan fake vs real score= 0.8031908543418569  prev_score= 0\n",
            "copulagan  synthetic vs real score 0.9072607723392673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:282: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:146: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:146: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:282: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:282: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:146: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  .fit(X)\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n",
            "/usr/local/lib/python3.7/dist-packages/ctgan/data_transformer.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[column_name] = data[column_name].to_numpy().flatten()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copulagan fake vs real score= 0.9182521563937891  prev_score= 0\n",
            "tvae  synthetic vs real score 0.9402935892811435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCp5WqlPOTfz",
        "outputId": "1c21b92b-c2a3-42b3-8ce0-18d1fbf8c7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}